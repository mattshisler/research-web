{
  "hash": "40c00ecda5f886864a8ed8ae7e7ffb50",
  "result": {
    "markdown": "---\ntitle: \"Step 7 - Areal data and the spatial CAR model - Basic Example\"\ndescription: \"A basic description and example of the spatial conditionally autoregressive model for areal data.\"\nauthor:\n  - name: Matthew Shisler\n    affiliation: North Carloina State University - Department of Statistics\n    affiliation-url: https://statistics.sciences.ncsu.edu/ \ncategories: [Bayesian, MCMC, Spatial, CAR] # self-defined categories\ndraft: false \nformat:\n  html: \n    code-fold: true\nexecute: \n  cache: true\n  freeze: auto\n---\n\n::: {.cell hash='index_cache/html/load-packages_3b26ab499e022fcada5e84a85e87f650'}\n\n```{.r .cell-code  code-summary=\"Code: Load the packages\"}\nlibrary(tidyverse)\nlibrary(igraph)\nlibrary(viridis)\nlibrary(MASS)\nlibrary(Matrix)\nlibrary(tictoc)\nlibrary(extraDistr)\nlibrary(CARBayes)\n```\n:::\n\n\n## A Brief Introduction\n\nHere we're going to examine the spatial CAR model. CAR stands for Conditionally Autoregressive. The *spatial* CAR model is in a way an extension of autoregressive models for time series data. Time series data is typically 1-dimensional (in time) and the observations have a natural ordering in the sense that observations can be ordered by the time they were observed. Spatial data can be any dimension and do not necessarily have a natural ordering.\n\n## What is areal data?\n\nA CAR model is commonly applied to areal data. That is data where the spatial domain $D$ is partitioned into a finite number of blocks or *areas*. A common example is the partition of the United States of America into states, census tracts, or counties. A measurement is then collected for each areal unit.\n\nThe spatial domain is $D$.\n\nThe areal units are $B_i$ for $i = 1,\\dots n$.\n\nThe measurements are $Z_i \\equiv Z(B_i)$ for $i = 1, \\dots, n$.\n\nBefore we dive into the distributional assumptions related to the CAR model, something must be said about the structure of the blocks. Namely we must define some notion of *proximity* from one block to the next. It's difficult in general to do this, particularly for an irregular partition of the spatial domain. The easiest approach is to define and *adjacency* matrix which captures which blocks are bordering other blocks. If there are $n$ blocks, then this adjacency matrix $\\mathbf{W}$ is $n \\times n$ and\n\n$$\nw_{ij} = \n\\begin{cases}\n1 \\quad \\text{if } B_i \\text{ shares a border with } B_j,\\\\\n0 \\quad \\text{otherwise}.\n\\end{cases}\n$$\nBy convention we say that an areal unit does not share a border with itself hence $w_{ii} = 0$ for all $i = 1, \\dots, n$.\n\nLet's define our own spatial domain and partition it into some very basic units.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_62fa3341425aabf3169ee0f3e6ba8a6e'}\n\n```{.r .cell-code}\nn <- 4\nspat_domain <- expand.grid(x = 1:n, y = 1:n)\nspat_domain$label <- 1:(n*n)\n```\n:::\n\n\nHere is the spatial domain. It is a regular lattice with 16 areal units.\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/fig-lattice-example_3cbca499ce6bd6444f0a192d1b8477ab'}\n\n```{.r .cell-code}\nggplot(spat_domain) +\n  geom_tile(aes(x, y), linewidth = 2, color = \"grey50\", fill=\"white\") +\n  geom_text(aes(x, y, label=label), size = 15) +\n  coord_fixed() + \n  theme_void()\n```\n\n::: {.cell-output-display}\n![A spatial domain partitioned into a regular lattice with areal units labeled $1,...,n$.](index_files/figure-html/fig-lattice-example-1.png){#fig-lattice-example fig-align='center' width=672}\n:::\n:::\n\n\nNext we want to define a neighborhood matrix for this regular lattice. A small digression, the convention used to label the areal units will impact the structure of this matrix. Is there a \"best\" structure? That remains to be seen. For now, let's stick with the adjacency matrix that arises from the ordering in figure above. Adjacency matrices are abundant in graph theory. We'll use the package `igraph` to construct the adjacency matrix for the areal units above. This is accomplished by first using `igraph` to create a 4 $\\times$ 4 lattice graph, then using the `as_adjacency_matrix` function to convert the graph object to a sparse matrix.\n\n\n::: {.cell hash='index_cache/html/fig-adjacent_mat_c1c0fe54a7618e05d67ce6a9247ab7a2'}\n\n```{.r .cell-code}\nspat_domain_g <- make_lattice(c(n,n), mutual = TRUE)\nW <- as_adjacency_matrix(spat_domain_g, sparse=1)\nW\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n16 x 16 sparse Matrix of class \"dgCMatrix\"\n                                     \n [1,] . 1 . . 1 . . . . . . . . . . .\n [2,] 1 . 1 . . 1 . . . . . . . . . .\n [3,] . 1 . 1 . . 1 . . . . . . . . .\n [4,] . . 1 . . . . 1 . . . . . . . .\n [5,] 1 . . . . 1 . . 1 . . . . . . .\n [6,] . 1 . . 1 . 1 . . 1 . . . . . .\n [7,] . . 1 . . 1 . 1 . . 1 . . . . .\n [8,] . . . 1 . . 1 . . . . 1 . . . .\n [9,] . . . . 1 . . . . 1 . . 1 . . .\n[10,] . . . . . 1 . . 1 . 1 . . 1 . .\n[11,] . . . . . . 1 . . 1 . 1 . . 1 .\n[12,] . . . . . . . 1 . . 1 . . . . 1\n[13,] . . . . . . . . 1 . . . . 1 . .\n[14,] . . . . . . . . . 1 . . 1 . 1 .\n[15,] . . . . . . . . . . 1 . . 1 . 1\n[16,] . . . . . . . . . . . 1 . . 1 .\n```\n:::\n:::\n\n\n\nWith the spatial domain defined and partitioned, we can continue by simulating spatial data. The most basic case assumes spatial independence.Let's also make it a bit more interesting by bumping up the number of areal units. Now it will probably be a lot easier to spot spatial dependence by a plot of the data alone.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_5066a2d9c55f958049a87df2f17a242b'}\n\n```{.r .cell-code}\nn <- 70\nspat_domain <- expand.grid(x = 1:n, y = 1:n)\nspat_domain$z <- rnorm(n^2, mean = 0, sd = 1)\nggplot(spat_domain) +\n  geom_tile(aes(x, y, fill=z)) +\n  scale_y_reverse() +\n  scale_fill_gradientn(colors = viridis(10)) +\n  coord_fixed() + \n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nWe want to simulate data *with* spatial dependence. We can do this from the CAR model.\n\nLet's turn to working with the CAR model through a simple example. Let \n\n$$\nZ_i =  \\mathbf{x}^T_i\\beta + \\phi_i + \\varepsilon_i\n$$\nHere we have a covariate vector $\\mathbf{x}_i$ indexed by spatial location $i$, $\\phi_i$ is a spatial random effect and $\\varepsilon_i$ is a random error associated with the measurement at location $i$ (later we assume to be normal with zero mean and constant variance). The defining characteristic of the CAR model is to specify a spatial structure through the conditional distributions of $\\phi_i$ accordingly\n\n$$\n\\phi_i|\\phi_{j, \\; j \\ne i} \\sim \\text{N}\\left(\\textstyle{\\frac{1}{n-1}\\sum}_{j \\ne i} \\phi_j, \\tau^2_i\\right)\n$$\nThat is the conditional mean of $\\phi_i$ is just the average of the spatial random effects across all other locations. That being said, it's probably not reasonable to condition on ALL other locations. Paraphrasing Tobler's First Law of Geography, \"everything is related to everything else, but near things are more related than distant things.\"\n\nPerhaps we don't need to condition on \"distant things.\" Instead we'll condition on only the locations we've defined as the neighbors of location $i$. Let $\\mathcal{N}_i$ be the set of locations that are considered neighbors with location $i$. Then we specify the conditional distribution as\n\n$$\n\\phi_i|\\phi_{j, j \\in \\mathcal{N}_i} \\sim \\text{N}\\left(\\textstyle{\\frac{1}{|\\mathcal{N}_i|}\\sum}_{j \\in \\mathcal{N}_i} \\phi_j, \\tau^2_i\\right)\n$$\nPractically, there are too many parameters in this model. Namely we have specified a location-specific variance, $\\tau^2_i$, in each conditional distribution. We can simplify the model by specifying the conditional variance as a function of a parameter shared across locations and the number of neighbors of a given location. This structure is intuitive because we would expect the conditional variance to decrease as the number of neighbors increases. The new conditional distributions are specified as\n\n$$\n\\phi_i|\\phi_{j, j \\in \\mathcal{N}_i} \\sim \\text{N}\\left(\\textstyle{\\frac{1}{|\\mathcal{N}_i|}\\sum}_{j \\in \\mathcal{N}_i} \\phi_j, \\frac{\\tau^2}{|\\mathcal{N}_i|}\\right)\n$$\nAt the end of the day it is possible to write the joint distribution of the spatial random effects from the conditional distributions. This is called *compatibility* and note that it is not guaranteed!  Let $\\boldsymbol\\phi = (\\phi_i,\\dots,\\phi_n)$, $\\mathbf{M}$ be an $n \\times n$ diagonal matrix containing the number of neighbors for each spatial location on its diagonal, and again $\\mathbf{W}$ is our proximity matrix we defined earlier. Finally, we need to introduce another parameter $\\rho$ to ensure that the distribution is proper (details in the BCG 2003).\n\n$$\n\\boldsymbol\\phi \\sim \\text{N}\\left(\\boldsymbol{0}, \\tau^2(\\mathbf{M} - \\rho \\mathbf{W})^{-1}\\right)\n$$\nThe matrix $\\mathbf{M}$ is fairly easy to obtain. Its diagonal is just the row sums from $\\mathbf{W}$ and all other terms set to 0.\n\nLet's try to simulate some data from this model. First we'll define the spatial domain.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-6_a0490a6421d03fc58190745acccd5141'}\n\n```{.r .cell-code}\nn      <- 70\nnsites <- n^2\nspat_domain <- expand.grid(x = 1:n, y = 1:n)\nspat_domain$label <- 1:nsites\nspat_domain_g <- make_lattice(c(n,n), mutual = TRUE)\nW <- as_adjacency_matrix(spat_domain_g, sparse=1)\n```\n:::\n\n\nNext define some parameters and draw from the spatial random effects distribution.\n\n::: {.cell hash='index_cache/html/unnamed-chunk-7_872e61c64ea02fafae189cced5da6db9'}\n\n```{.r .cell-code}\ntau2 <- 5\nrho <- 0.99\nM   <- diag(rowSums(W))\nspat_prec <- (1/tau2)*(M-rho*W) # swap this with something else. . .\nspat_domain$phi <- backsolve(chol(spat_prec), matrix(rnorm(nsites), nrow = nsites))\n# spat_cov <- tau^{-2}*solve(M-rho*W)\n# \n# phi <- MASS::mvrnorm(1, mu = rep(0,n^2), Sigma = spat_cov)\n```\n:::\n\n\nNext sample the observations from the data distribution.\n\n::: {.cell hash='index_cache/html/unnamed-chunk-8_16f612487c474e21ebecd343d53aa48a'}\n\n```{.r .cell-code}\nX    <- rep(1, nsites)\nbeta <- matrix(c(2), nrow = 1)\nsigma2 <- 5\nspat_domain$z  <- rnorm(nsites, mean = X%*%beta + spat_domain$phi, sd = sqrt(sigma2))\n```\n:::\n\n\nLet's generate some plots. First, the spatial random effects, then the observations.\n\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/unnamed-chunk-9_371ab3ad7d62c1eef8f8aa2f7fb0ee4b'}\n\n```{.r .cell-code}\nggplot(spat_domain) +\n  geom_tile(aes(x, y, fill=phi)) +\n  scale_y_reverse() +\n  scale_fill_gradientn(colors = viridis(10)) +\n  coord_fixed() + \n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=672}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/unnamed-chunk-10_b8ed158b1bf39af12ad27c38a97c08f1'}\n\n```{.r .cell-code}\nggplot(spat_domain) +\n  geom_tile(aes(x, y, fill=z)) +\n  scale_y_reverse() +\n  scale_fill_gradientn(colors = viridis(10)) +\n  coord_fixed() + \n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\nSo we've simulated some data from the CAR model and it seems fairly clear that the measurements are spatially correlated. Now we want to fit a CAR model to this data and estimate the parameters, $\\boldsymbol\\theta = (\\beta, \\sigma^2, \\tau^2, \\rho)$.\n\nWe can do this using MCMC. First, let's summarize the hierarchical model.\n\n\n\\begin{align*}\nZ_i &\\sim \\text{N}\\left(x^T_i\\boldsymbol\\beta + \\phi_i, \\; \\sigma^2\\right)\\\\\n\\mu &\\sim \\text{N}\\left(0, \\lambda^2\\right)\\\\\n\\phi_i|\\phi_{j \\in \\mathcal{N}_i} &\\sim \\text{N}\\left(\\frac{\\rho}{m_i}\\sum_{j\\in \\mathcal{N}_i} \\phi_j, \\frac{\\tau^2}{m_i} \\right)\\\\\n\\sigma^2 &\\sim \\text{IG}\\left(a, b\\right)\\\\\n\\tau^2 &\\sim \\text{IG}\\left(a,b\\right)\\\\\n\\rho &\\sim \\text{Unif}\\left(0,1\\right)\n\\end{align*}\n\n\nWe've stated the model using conditional distributions of $\\phi_i$, though we learned earlier that it is possible to write the joint distribution of $\\boldsymbol\\phi$. If we do this, we will at some point to need invert a very large matrix in order to sample from the full conditional for $\\boldsymbol\\phi$. Instead it might be faster to cycle through the full conditionals of $\\phi_i$ for each $i$.\n\nMost of this model can be implemented using Gibbs sampling, except when sampling the $\\rho$ parameter. We'll need to use a Metropolis-Hastings step for that. The full conditionals are as follows,\n\n\n\\begin{align*}\n\\boldsymbol\\beta|\\text{rest} &\\sim \\text{N}\\left(\\mathbf{B}^{-1}\\mathbf{A}, \\mathbf{B}^{-1}\\right)\\\\\n\\mathbf{A} &= \\sigma^{-2} \\mathbf{X}^T(Z - \\boldsymbol\\phi)\\\\\n\\mathbf{B} &= \\sigma^{-2}\\mathbf{X}^T\\mathbf{X} + \\lambda^{-2}\\mathbf{I}\\\\\n\\\\\\\\\n\\phi_i|\\text{rest} &\\sim \\text{N}\\left(\\frac{A}{B}, \\frac{1}{B}\\right)\\\\\nA &= \\frac{\\rho}{\\tau^2}\\sum_{j \\in \\mathcal{N}_i}\\phi_j + \\frac{1}{\\sigma^2}(Z_i - x_i^T\\boldsymbol\\beta)\\\\\nB &= \\frac{m_i}{\\tau^2} + \\frac{1}{\\sigma^2}\\\\\n\\\\\\\\\n\\sigma^2|\\text{rest} &\\sim \\text{IG}\\left(A, B \\right)\\\\\nA &= a + \\frac{n}{2}\\\\\nB &= b + \\frac{1}{2}(Z-\\mathbf{X}\\boldsymbol\\beta-\\phi)^T(Z-\\mathbf{X}\\boldsymbol\\beta-\\boldsymbol\\phi)\\\\\n\\\\\\\\\n\\tau^2|\\text{rest} &\\sim \\text{IG} \\left(A, B\\right)\\\\\nA &= a + \\frac{n}{2}\\\\\nB &= b + \\frac{1}{2}\\sum_{i=1}^n m_i\\left(\\phi_i - \\frac{\\rho}{m_i}\\sum_{j \\in \\mathcal{N}_i}\\phi_j\\right)^2\\\\\n\\\\\\\\\np(\\rho|\\text{rest}) &\\propto \\left[\\prod_{i=1}^n p(\\phi_i|\\phi_{j, j\\in\\mathcal{N}_i}, \\rho)\\right]p(\\rho)\\\\\n&\\propto \\exp\\left\\{-\\frac{1}{2\\tau^2} \\sum_{i=1}^n m_i \\left(\\phi_i - \\frac{\\rho}{m_i}\\sum_{j \\in \\mathcal{N}_i} \\phi_j \\right)^2\\right\\} \\mathbf{1}\\left\\{\\rho \\in [0,1]\\right\\}\n\\end{align*} \n\n\nClearly we are unable to sample directly from the full conditional for $\\rho$. Instead we will need to implement a Metropolis-Hasting step. We will use a truncated normal proposal distribution from the pacakge `extraDistr` to match the support of $\\rho$. This also let's us \"ignore\" the indicator function in the uniform prior because we will never propose a candidate value outside of $[0,1]$.\n\nAs an aside, we will need to routinely compute averages of neighboring spatial random effects at each location. Rather than extract neighbor information from a large neighbor matrix, we define `ineighbors` as a list of vectors containing the neighbor indices for each location. Additionally we create `nneighbors` as a vector containing the number of neighbors for each location. These two objects together should give us all we need to efficiently sample full conditionals.\n\n::: {.cell hash='index_cache/html/unnamed-chunk-11_4fc7aa0caad1758e7839d74c22d999a9'}\n\n```{.r .cell-code}\nn <- 10\nnsites <- n^2\nspat_domain <- expand.grid(x = 1:n, y = 1:n)\nspat_domain$label <- 1:(n*n)\nspat_domain_g <- make_lattice(c(n,n), mutual = TRUE)\nW <- as_adjacency_matrix(spat_domain_g, sparse=1)\nineighbors <- apply(W, MARGIN = 1, FUN = function(x) which(x==1))\nnneighbors <- rowSums(W)\n```\n:::\n\n\nFirst, simulate a small data set.\n\nNext sample the spatially independent and spatially dependent covariates.\n\n::: {.cell hash='index_cache/html/unnamed-chunk-12_f3cc3323b8d731c5350539bc4dfd2131'}\n\n```{.r .cell-code}\n# spatially independent\n# x1 <- rnorm(nsites, mean = 0, sd = 1)\nX <- matrix(1, nrow = nsites)\n# spatial random effect\ntau20 <- 4\nrho0  <- 0.99\nM     <- diag(rowSums(W))\nspat_prec <- (1/tau20)*(M-rho0*W) # swap this with something else. . .\nspat_domain$phi <- backsolve(chol(spat_prec), matrix(rnorm(nsites), nrow = nsites))\nphi0 <- spat_domain$phi\n```\n:::\n\n\nNext sample the observations from the data distribution.\n\n::: {.cell hash='index_cache/html/unnamed-chunk-13_d99684274cc9b207c5959b83d59ea067'}\n\n```{.r .cell-code}\nbeta0   <- 2\nsigma20 <- 0.25\nspat_domain$z  <- rnorm(nsites, mean = X%*%beta0 + spat_domain$phi, sd = sqrt(sigma20))\nz <- matrix(spat_domain$z, nrow = nsites)\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-14_e3b907a2485ef1897c6972301e58ada9'}\n\n```{.r .cell-code}\nnpars  <- length(beta)\nnsites <- n^2\nniters <- 5000\nburn   <- 1000\nkeep_beta   <- matrix(NA, nrow = niters, ncol = npars)\nkeep_phi    <- matrix(NA, nrow = niters, ncol = nsites)\nkeep_sigma2 <- rep(NA, niters)\nkeep_tau2   <- rep(NA, niters)\nkeep_rho    <- rep(NA, niters)\n\n# initial values\nbeta   <- keep_beta[1,]  <- 2 #beta0\nphi    <- keep_phi[1,]   <- rep(10, nsites)\nsigma2 <- keep_sigma2[1] <- 2   #sigma20\ntau2   <- keep_tau2[1]   <- 5  # tau20\nrho    <- keep_rho[1]    <- rho0\n\n# prior parameters\na <- 0.1\nb <- 0.1\nlambda2 <- 10000\n\n# Metropolis-Hastings\natt <- 0\nacc <- 0\nMH  <- 0.1\n\n# pre-computes\nXtX <- t(X)%*%X\n\n\n## TODO:\n##    - review rho_loglike funtion.\n# rho_loglike <- function(rho, phi, ineighbors, nneighbors){\n# \n#   sneighbors <- sapply(ineighbors, FUN = function(x) sum(phi[x]))\n#   aneighbors <- sneighbors/nneighbors\n#   \n#   t1 <- sum(nneighbors*phi^2)\n#   t2 <- 2*rho*sum(phi*sneighbors)\n#   t3 <- (rho^2)*sum(nneighbors*(sneighbors^2))\n#   \n#   return(t1 - t2 + t3)\n# }\n\n\ntic()\nfor(iter in 2:niters){\n  \n  # sample mu [Gibbs]\n  A     <- (1/sigma2)*(t(X)%*%(z-phi))\n  B_inv <- solve((1/sigma2)*XtX + (1/lambda2)*diag(npars))\n  beta  <- B_inv%*%A+t(chol(B_inv))%*%rnorm(npars)\n  # beta <- beta0\n  \n  # sample phi [Gibbs]\n  for (site in 1:nsites){\n    A         <- (rho/tau2)*sum(phi[ineighbors[[site]]]) + \n                 (1/sigma2)*(z[site] - X[site,]%*%beta)\n    B_inv     <- 1/(nneighbors[site]/tau2 + 1/sigma2) \n    phi[site] <- rnorm(1, mean = B_inv*A, sd = sqrt(B_inv))\n  }\n  # phi <- phi0\n  \n  # sample sigma2 [Gibbs]\n  A      <- a + (nsites/2)\n  B      <- b + (1/2)*sum((z - X%*%beta - phi)^2)\n  sigma2 <- 1/rgamma(1, A, B)\n  # sigma2 <- sigma20\n  \n  # sample tau2 [Gibbs]\n  aneighbors <- sapply(ineighbors, FUN = function(x) sum(phi[x]))/nneighbors\n  A    <- a + (nsites/2)\n  B    <- b + (1/2)*sum(nneighbors*(phi - rho*aneighbors)^2)\n  tau2 <- 1/rgamma(1, A, B)\n  # tau2 <- tau20\n  \n  ## TODO:\n  ##    - review rho M-H step. Fix rho for now.\n  ## sample rho [M-H]\n  # att <- att + 1 \n  # can <- rtnorm(1, rho, MH, a = 0, b = 1)\n  # R   <- rho_loglike(can, phi, ineighbors, nneighbors) - # Likelihood\n  #        rho_loglike(rho, phi, ineighbors, nneighbors) +\n  #        dtnorm(rho, can , a = 0, b = 1, log = T) -      # M-H adjustment\n  #        dtnorm(can, rho , a = 0, b = 1, log = T)\n  # if(log(runif(1)) < R){\n  #   acc <- acc + 1\n  #   rho <- can\n  # }\n  # rho <- rho0\n  # \n  # # tuning\n  # if(iter < burn){\n  #   if(att > 50){\n  #     if(acc/att < 0.3){MH <- MH*0.8}\n  #     if(acc/att > 0.6){MH <- MH*1.2}\n  #     acc <- att <- 0\n  #   }\n  # }\n  rho <- rho0\n  \n  # storage\n  keep_beta[iter,]  <- beta\n  keep_phi[iter,]   <- phi\n  keep_sigma2[iter] <- sigma2\n  keep_tau2[iter]   <- tau2\n  keep_rho[iter]    <- rho\n  \n}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n4.64 sec elapsed\n```\n:::\n:::\n\n\nNow let's inspect some trace plots.\n\n::: {.cell hash='index_cache/html/unnamed-chunk-15_40369f8a926e0517bd71d77bbe370e38'}\n\n```{.r .cell-code}\nwin = 1:niters\nplot(win, keep_beta[win,1], type = \"l\")\nabline(h = beta0[1], col = \"red\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(win, keep_sigma2[win], type = \"l\")\nabline(h = sigma20, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(win, keep_tau2[win], type = \"l\")\nabline(h = tau20, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(win, keep_rho[win], type = \"l\")\nabline(h = rho0, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-4.png){width=672}\n:::\n:::\n\n\nCheck trace plots for $\\phi$. 10 random locations.\n\n::: {.cell hash='index_cache/html/unnamed-chunk-16_285c89f90442518e8a11cebe06b703ec'}\n\n```{.r .cell-code}\nsampled_sites <- sample(1:nsites, size = 10)\nfor (site in sampled_sites){\n  plot(win, keep_phi[win, site] + keep_beta[win,1], type = \"l\")\n  abline(h = phi0[site], col = \"red\")\n}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-4.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-5.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-6.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-7.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-8.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-9.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-10.png){width=672}\n:::\n:::\n\n\nThere's clearly something wrong. I'll need to revisit this and verify the derivations and/or debug the code.\n\nWhat if we compared to the CARBayes package? Note that CARBayes uses a modified version of the model proposed by Leroux (cite)\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-17_6af2aa8d797ed62b4f525c6d73247a2c'}\n\n```{.r .cell-code}\n# convert neighbord matrix from sparse dgCMatrix format.\nW <- as.matrix(W)\n# fit model from CARBayes.\ncb.model <- S.CARleroux(z~1, family = \"gaussian\", \n                        W=W, burnin = 1000, n.sample = 5000, \n                        rho = rho0, verbose = FALSE)\ncb.model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n#################\n#### Model fitted\n#################\nLikelihood model - Gaussian (identity link function) \nRandom effects model - Leroux CAR\nRegression equation - z ~ 1\nNumber of missing observations - 0\n\n############\n#### Results\n############\nPosterior quantities and DIC\n\n              Mean   2.5%  97.5% n.effective Geweke.diag\n(Intercept) 2.9989 2.8790 3.1165      4675.6        -1.1\nnu2         0.2900 0.0034 1.0582        25.2         0.5\ntau2        3.3438 1.0646 5.3418        31.6        -0.4\nrho         0.9900 0.9900 0.9900          NA          NA\n\nDIC =  27.7571       p.d =  -26.96194       LMPL =  -114.25 \n```\n:::\n:::\n\n\nLet's look at the CARbayes samples...\n\n::: {.cell hash='index_cache/html/unnamed-chunk-18_25b72991a1d822327804615eac41775d'}\n\n```{.r .cell-code}\nplot(cb.model$samples$beta)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(cb.model$samples$nu2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(cb.model$samples$tau2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# plot(cb.model$samples$phi)\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}