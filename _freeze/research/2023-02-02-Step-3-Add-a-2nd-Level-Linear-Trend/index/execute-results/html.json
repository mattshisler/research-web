{
  "hash": "52929877d81aae7a9343cfc6138cd91a",
  "result": {
    "markdown": "---\ntitle: \"Step 3 - Add a Second Level Linear Trend\"\ndescription: \"In this extension we add a linear trend to the second level of the hierarchical model and re-derive the full conditionals.\"\nauthor:\n  - name: Matthew Shisler\n    affiliation: North Carloina State University - Department of Statistics\n    affiliation-url: https://statistics.sciences.ncsu.edu/ \ncategories: [Bayesian, MCMC, Hierarchical Model] # self-defined categories\ndraft: false \nformat:\n  html: \n    code-fold: true\nexecute: \n  cache: true\n  freeze: auto\n---\n\n::: {.cell hash='index_cache/html/load-packages_33d89cbae04dd9557210b6bf96e1061f'}\n\n```{.r .cell-code  code-summary=\"Code: Load the packages\"}\nlibrary(tictoc)\nlibrary(Rfast)\n```\n:::\n\n\nBriefly restating notation from earlier, $\\mathbf{Y}_i$ is an $n_i \\times 1$ response vector , $\\mathbf{X}$ an $m \\times p$ parent design matrix, and $\\boldsymbol\\delta_i$ a $p \\times 1$ parameter vector corresponding to subject $i = 1,\\dots,N$. The matrix $\\widetilde{\\mathbf{X}}_i$ is an $n_i \\times p$ matrix associated with subject $i$ which is construct with a sample of rows from the parent design matrix $\\mathbf{X}$. The entries of $\\mathbf{Y}_i$ are mutually independent with constant variance $\\sigma^2$, $\\text{Cov}(\\mathbf{Y}_i) = \\sigma^2 \\mathbf{I}_{n_i}$ for all $i$. Further, $\\mathbf{Y}_1,\\dots,\\mathbf{Y}_N$ are mutually independent.\n\nIn this step we will add a linear trend to the mean of the distribution for $\\boldsymbol\\delta_i$. There will be more parameters to estimate and some modification to the full conditionals for the Gibbs sampler. Let $\\mathbf{z}_i$ be a $q \\times 1$ vector of covariates, including an intercept element in the first position.\n\nThe linear trend in the random effects distribution for $\\boldsymbol\\delta_i$ is represented as a linear combination $\\sum_{l=1}^q\\boldsymbol\\beta_l z_{il}$ where $\\boldsymbol\\beta_l$ are $p \\times 1$ vectors. There are two ways to write this expression in matrix notation. Let $\\boldsymbol\\beta = (\\boldsymbol\\beta_1^T, \\boldsymbol\\beta_2^T, \\dots, \\boldsymbol\\beta_q^T)^T$ be the $qp \\times 1$ vector of stacked $\\boldsymbol\\beta_i$ vectors and let $\\mathbf{B} = [\\boldsymbol\\beta_1 \\;\\;\\; \\boldsymbol\\beta_2 \\;\\;\\; \\dots \\;\\;\\; \\boldsymbol\\beta_q]$ be the $p \\times q$ matrix of arranged $\\boldsymbol\\beta_i$ vectors. Note, $\\boldsymbol\\beta = \\text{vec}(\\mathbf{B})$.  Either we write\n\n\\begin{equation}\n\\tag{1}\n\\boldsymbol{\\mathcal{Z}}_i\\boldsymbol\\beta = \n\\begin{bmatrix}\n1 & \\dots & 0 & z_{i2} & \\dots & 0 & & z_{iq} & \\dots & 0\\\\\n\\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots & \\dots & \\vdots & \\ddots & \\vdots\\\\\n0 & \\dots & 1 & 0 & \\dots & z_{i2} & & 0 & \\dots & z_{iq}\n\\end{bmatrix}_{p \\, \\times \\, qp}\n\\begin{bmatrix}\n\\boldsymbol\\beta_1\\\\\n\\boldsymbol\\beta_2\\\\\n\\vdots\\\\\n\\boldsymbol\\beta_q\n\\end{bmatrix}_{qp \\, \\times \\, 1}\n\\end{equation}\nor we could write\n\\begin{equation}\n\\tag{2}\n\\mathbf{B}\\mathbf{z}_i =\n\\begin{bmatrix}\n\\boldsymbol\\beta_1 & \\boldsymbol{\\beta}_2 & \\dots & \\boldsymbol\\beta_q\n\\end{bmatrix}_{p \\,\\times \\, q}\n\\begin{bmatrix}\n1\\\\\nz_{i2}\\\\\n\\vdots\\\\\nz_{iq}\n\\end{bmatrix}_{q \\, \\times \\, 1}\n\\end{equation}\n\nThe former is attractive for deriving analytical expressions and the latter is attractive for some computational advantages. The model is defined to be as follows,\n\n\\begin{align*}\n\\mathbf{Y}_i &\\sim \\text{Normal}_{n_i}\\left(\\widetilde{\\mathbf{X}}_i\\boldsymbol\\delta_i, \\; \\sigma^2 \\mathbf{I}_{n_i}\\right)\\\\\n\\boldsymbol\\delta_i &\\sim \\text{Normal}_p\\left(\\boldsymbol{\\mathcal{Z}}_i\\boldsymbol\\beta, \\; \\mathbf{\\Omega}\\right)\n\\end{align*}\n\nAgain, we will assume $\\mathbf{\\Omega}$ is diagonal and let $\\omega_{kk}$ be the $k$th diagonal element. Next we specify priors,\n\\begin{align*}\n\\boldsymbol\\beta &\\sim \\text{Normal}_{qp}\\left(\\boldsymbol\\mu, \\; \\mathbf{\\Lambda}\\right)\\\\\n\\omega_{kk} &\\sim \\text{InvGamma}\\left(a_\\omega, \\; b_\\omega \\right)\\\\\n\\sigma^2 &\\sim \\text{InvGamma}\\left(a_\\sigma, \\; b_\\sigma\\right)\n\\end{align*}\n\nThe full conditionals in this model are as follows,\n\n\\begin{align*}\n\\boldsymbol\\delta_i|\\text{ rest} &\\sim \\text{Normal}_p(\\mathbf{V}_i^{-1}\\mathbf{M}_i, \\mathbf{V}_i^{-1})\\\\\n\\mathbf{V}_i &= \\frac{1}{\\sigma^2} \\widetilde{\\mathbf{X}}_i^T\\widetilde{\\mathbf{X}}_i + \\mathbf{\\Omega}^{-1}\\\\\n\\mathbf{M}_i &= \\frac{1}{\\sigma^2} \\widetilde{\\mathbf{X}}_i^T\\mathbf{Y}_i + \\mathbf{\\Omega}^{-1}\\boldsymbol{\\mathcal{Z}}_i\\boldsymbol\\beta\\\\\\\\\n\\boldsymbol\\beta|\\text{ rest} &\\sim \\text{Normal}_p(\\mathbf{V}_\\beta^{-1}\\mathbf{M}_\\beta, \\mathbf{V}_\\beta^{-1})\\\\\n\\mathbf{V}_\\beta &= \\sum_{i=1}^N\\boldsymbol{\\mathcal{Z}}^T_i\\mathbf{\\Omega}^{-1}\\boldsymbol{\\mathcal{Z}}_i + \\mathbf{\\Lambda}^{-1}\\\\\n\\mathbf{M}_\\beta &= \\sum_{i=1}^N\\boldsymbol{\\mathcal{Z}}^T_i\\mathbf{\\Omega}^{-1}\\boldsymbol\\delta_i + \\mathbf{\\Lambda}^{-1}\\boldsymbol\\mu\\\\\\\\\n\\omega_{kk}|\\text{ rest} &\\sim \\text{InvGamma}(A_\\omega,B_\\omega)\\\\\nA_\\omega &= N/2 + a_\\omega\\\\\nB_\\omega &= \\frac{1}{2}\\sum_{i=1}^N (\\delta_{ik} - (\\boldsymbol{\\mathcal{Z}}_i\\boldsymbol\\beta)_k)^2 + b_\\omega\\\\\\\\\n\\sigma^2|\\text{ rest} &\\sim \\text{InvGamma}(A_\\sigma,B_\\sigma)\\\\\nA_\\sigma &= \\frac{1}{2}\\sum_{i=1}^N n_i + a_\\sigma\\\\\nB_\\sigma &= \\frac{1}{2}\\sum_{i=1}^N (\\mathbf{Y}_i - \\widetilde{\\mathbf{X}}_i\\boldsymbol\\delta_i)^T(\\mathbf{Y}_i - \\widetilde{\\mathbf{X}}_i\\boldsymbol\\delta_i) + b_\\sigma\n\\end{align*}\n\nA few computational remarks, in the full conditional for $\\boldsymbol\\beta$, we have the expression $\\sum_{i=1}^N\\boldsymbol{\\mathcal{Z}}^T_i\\boldsymbol\\Omega^{-1}\\boldsymbol{\\mathcal{Z}}_i$ which would be much too naive to compute directly for each MCMC iteration. Instead, we will rewrite this expression in such a way that will allow us to simplify computations inside the Gibbs loop. First, consider a different and perhaps more natural organization of the covariates $\\mathbf{z}_i$, into a matrix $\\mathbf{Z} = (\\mathbf{z}_1^T, \\dots,\\mathbf{z}_N^T)^T$\n\\begin{equation}\n\\tag{3}\n\\mathbf{Z} = \n\\begin{bmatrix}\n1 & z_{12} & \\dots & z_{1q}\\\\\n\\vdots & & \\vdots &\\\\\n1 & z_{N2} & \\dots & z_{Nq}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\mathbf{z}_1^T\\\\\n\\vdots\\\\\n\\mathbf{z}_N^T\\\\\n\\end{bmatrix}\n\\end{equation}\n\nLet $\\otimes$ represent the Kronecker product. The following identity holds,\n\\begin{equation}\n\\tag{4}\n\\sum_{i=1}^N\\boldsymbol{\\mathcal{Z}}^T_i\\boldsymbol\\Omega^{-1}\\boldsymbol{\\mathcal{Z}}_i = \\mathbf{Z}^T\\mathbf{Z} \\otimes \\boldsymbol\\Omega^{-1}\n\\end{equation}\n\nWith $\\mathbf{Z}$ known we can compute $\\mathbf{Z}^T\\mathbf{Z}$ outside of the Gibbs loop. \n\nAlso in the full conditional for $\\boldsymbol\\beta$ we have the expression $ \\sum_{i=1}^N\\boldsymbol{\\mathcal{Z}}^T_i\\mathbf{\\Omega}^{-1}\\boldsymbol\\delta_i$. Unfortunately, with $\\boldsymbol\\delta_i$ and $\\boldsymbol\\Omega^{-1}$ being parameters to update, this expression must be fully evaluated at each MCMC iteration. Let $\\boldsymbol\\Delta = (\\boldsymbol\\delta_1,\\dots,\\boldsymbol\\delta_N)$ be the $p \\times N$ matrix of arranged parameter vectors, $\\boldsymbol\\delta_i$, and $\\mathbf{Z}$ be defined as before in $(3)$. A useful identity in computing the quantity of interest is\n\\begin{equation}\n\\tag{5}\n\\sum_{i=1}^N\\boldsymbol{\\mathcal{Z}}^T_i\\mathbf{\\Omega}^{-1}\\boldsymbol\\delta_i =  \\text{vec}(\\Omega^{-1}\\boldsymbol\\Delta\\mathbf{Z}) = (\\mathbf{Z}^T \\otimes \\, \\boldsymbol\\Omega^{-1})\\text{vec}(\\boldsymbol\\Delta).\n\\end{equation}\n\nFor the other full conditionals in which $\\boldsymbol{\\mathcal{Z}}_i\\boldsymbol\\beta$ appears, namely $\\boldsymbol\\delta_i$ and $\\omega_{kk}$, we can replace with appropriate and readily computed form $\\mathbf{B}\\mathbf{z}_i$ as defined in $(2)$.\n\nSimulate some data from this model. In this case will we set $p = 2$, $q = 2$, $N = 100$, $n_i = n = 100$, and $m = 400$. \n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_43b673bd1a4f970c60b53bea6e2d0f72'}\n\n```{.r .cell-code  code-summary=\"Simulate the data\"}\n# dimensions\nN <- 100\nm <- 400\nn <- rep(100, N)\np <- 2\nq <- 2\n\n# Design matrices\nXp <- matrix(c(rep(1,m), rnorm(m*(p-1), mean = 0, sd = 5)), nrow = m, ncol = p)\nZ  <- matrix(c(rep(1,N), rnorm(N*(q-1), mean = 0, sd = 5)), nrow = N, ncol = q)\n\n# beta parameters\nB0     <- Rfast::rmvnorm(q, rep(0,p), (5^2)*diag(2))\nbeta0  <- matrix(c(B0), ncol = 1)\nOmega0 <- diag(c(2,1))\n\n# delta parameters\ndelta0  <- matrix(0, nrow = p, ncol = N)\nsigma20 <- 1\n\n# sample data\nY <- list()\nX <- list()\nfor (i in 1:N){\n  # draw delta\n  delta0[,i]   <- t(Rfast::rmvnorm(1, B0%*%Z[i,], Omega0))\n  \n  # draw rows from parent X\n  subject_rows <- sample(1:m, n[i])\n  X[[i]] <- Xp[subject_rows,]\n  \n  # draw response\n  Y[[i]] <- matrix(rnorm(n[i], mean = X[[i]]%*%delta0[,i], sd = sqrt(sigma20)), ncol=1)\n}\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_b8123e258003fe1a1fae53e5aec94b9c'}\n\n```{.r .cell-code  code-summary=\"Run the Gibbs Sampler\"}\n# set-up\nniter <- 5000\nkeep_delta  <- array(NA, dim = c(p, N, niter))\nkeep_B      <- array(NA, dim = c(p, q, niter))\nkeep_Omega  <- matrix(NA, nrow = niter, ncol = p)\nkeep_sigma2 <- rep(NA, niter)\n\n# initial values\ndelta  <- matrix(0, nrow = p, ncol = N)\nbeta   <- rep(10, q*p)\nB      <- matrix(c(beta), nrow=p)\nsigma2 <- 3\nOmega  <- diag(c(5,5))\nkeep_delta[,,1] <- delta\nkeep_B[,,1]     <- B\nkeep_Omega[1,]  <- diag(Omega)\nkeep_sigma2[1]  <- sigma2\n\n# prior parameters\nmu    <- rep(0, q*p)\nLambda_inv <- diag(rep(1e-06,q*p))\na     <- 0.1\nb     <- 0.1\n\n# pre-computes\nXtX <- list()\nXtY <- list()\nfor (k in 1:N){\n  XtX[[k]] <- t(X[[k]])%*%X[[k]]\n  XtY[[k]] <- t(X[[k]])%*%Y[[k]]\n}\nZtZ <- t(Z)%*%Z\nLmu <- Lambda_inv%*%mu\nAo    <- N/2 + a\nAs    <- sum(n)/2 + a\n\ntic()\n# Gibbs Loop\nfor (iter in 2:niter){\n\n  Omega_inv <- diag(1/diag(Omega))\n  \n  # sample deltas\n  for (i in 1:N){\n    M         <- (1/sigma2)*XtY[[i]] + Omega_inv%*%B%*%Z[i,]\n    V_inv     <- chol2inv(chol((1/sigma2)*XtX[[i]] + Omega_inv))\n    delta[,i] <- V_inv%*%M+t(chol(V_inv))%*%rnorm(p)\n  }\n  \n  # sample beta\n  M     <- kronecker(t(Z), Omega_inv)%*%matrix(c(delta), ncol = 1) + Lmu\n  V_inv <- solve(kronecker(ZtZ, Omega_inv) + Lambda_inv)\n  beta  <- V_inv%*%M+t(chol(V_inv))%*%rnorm(q*p)\n  B     <- matrix(beta, nrow = p)\n  \n  # sample omegas\n  for (k in 1:p){\n    Bo <- sum((delta[k,] - (B%*%t(Z))[k,])^2)/2 + b\n    Omega[k,k] <- 1/rgamma(1, Ao, Bo)\n  }\n  \n  # sample sigma2\n  SSE <- 0\n  for (i in 1:N){\n    SSE <- SSE + sum((Y[[i]] - X[[i]]%*%delta[,i])^2)\n  }\n  Bs <- SSE/2 + b\n  sigma2 <- 1/rgamma(1, As, Bs)\n  \n  # store everything\n  keep_delta[,,iter] <- delta\n  keep_B[,,iter]     <- B\n  keep_Omega[iter,]  <- diag(Omega)\n  keep_sigma2[iter]  <- sigma2\n}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n21.13 sec elapsed\n```\n:::\n:::\n\n\nNow for some trace plots. The following are for $\\mathbf{B}$, $\\boldsymbol\\Omega$, and $\\sigma^2$. And display iterations 100:5000. This visual inspection seems to indicate good convergence!\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_fefd17f609dd7663071825582cf54a40'}\n\n```{.r .cell-code  code-summary=\"Construct Trace Plots\"}\nwin <- 100:niter\n\npar(mfrow = c(2,2))\n\nfor(l in 1:q){\n  for (k in 1:p){\n    plot(win, keep_B[k, l, win], type = \"l\",\n         ylab = bquote(beta[paste(.(l),\",\",.(k))]),\n         xlab = \"iter\")\n    abline(h = B0[k, l], col = \"red\")\n  }\n}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code  code-summary=\"Construct Trace Plots\"}\nfor (k in 1:p){\n  plot(win, keep_Omega[win, k], type = \"l\",\n       ylab = bquote(omega[paste(.(k),\",\",.(k))]),\n       xlab = \"iter\")\n  abline(h = Omega[k, k], col = \"red\")\n}\n\nplot(win, keep_sigma2[win], type = \"l\",\n     ylab = bquote(sigma^2),\n     xlab = \"iter\")\nabline(h = sigma20, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}